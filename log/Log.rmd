---
author: Lisa Hu
output:
  pdf_document:
    includes:
      before_body: title.sty
    keep_tex : true
    toc: true
    toc_depth: 2
    number_sections: true
    latex_engine: xelatex
---
```{r include = FALSE}
# Copyright (c) 2022 Lisa Hu
# Licensed under GPLv3. See LICENSE
```

```{r setup, include = FALSE, warning = FALSE, message = FALSE, results = "hide"}
#' Setup chunk
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::read_chunk("EDA.R")
```
[//]: # (toc)

\newpage
```{r libraries, warning = FALSE, message = FALSE, include = FALSE}
#' Load all the packages
packages <- c("dplyr", "ggplot2", "readr", "ggpubr", "pander", "ggbiplot", "FSA")
invisible(lapply(packages, library, character.only = T))
```

# Data description
The data can be found on kaggle.com: [Urinary biomarkers for pancreatic cancer](https://www.kaggle.com/datasets/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer)
The files are saved as `Data.csv` and `Documentation.csv` for easier access.

The following packages were used:

+ dplyr
+ readr
+ pander
+ FSA
+ ggplot2
+ ggpubr
+ ggbiplot

# Reading the data
We first want to create an insight of our data:
```{r read-data}
```

The information given in the codebook originates from the `Documentation.csv`. This file was given with the data file and can be found on the website.

\newpage
# Manipulate the data
A lot of the rows contain empty strings instead of NA, which has to be fixed first. Besides that, the columns `sample_id` , `patient_cohort`, `sample_origin`, and `benign_sample_diagnosis` in the dataset significant value for the analysis and are therefor dropped. A column `diagnosis_group` was added for a comparison test.

```{r change-data}
```

\newpage
## REG1A vs. REG1B
```{r reg-vs}
```

Although performance between the two is similar, a Kruskal-Wallis test with Dunn's multiple comparisons shows that REG1B outperforms REG1A when the control and benign samples are compared to the I-IIA PDAC samples. Therefor, REG1B was used further on in the experiments and REG1A is dropped.

## Log transformation
A summary of the data shows very high maximum values, but rather low medians. A log-transformation is applied to correct this.

```{r log-trans}
```

The samples are then grouped by diagnosis for easier access of the different samples. Table 5 shows the different amounts of samples per diagnosis and the amount of which are also blood samples. After the blood samples are seperated the column can be dropped.
\newpage
```{r demograph}
```

\newpage
# Analyse the data
## Boxplots
```{r exp-box, fig.height = 8}
```

The outliers are not localized in a specific diagnosis group, but rather spread over the groups.

\newpage

## Correlation matrix
```{r correlation}
```

The heatmap shows that there is not much correlation between creatinine and the other variables. The other outstanding one has to be the TFF1 biomarker, being the most correlated variable to others.

\newpage

## PCA
```{r pca}
```

While the control and benign group show relative distance from the PDAC group, there is a still a lot of overlapping samples with the benign and PDAC groups. As earlier concluded from the heatmap, the creatinine biomarker does not show much relativeness with the other biomarkers. LYVE1 is nicely in between the TFF1 and REG1B biomarkers. Every point close tho the origin have values close to the mean for all variables.

\newpage
# Machine Learning
## Model exploration
For the exploration of the model, the data is cleaned it contains only the biomarkers and the classification labels (Control, Benign, I-II, and III-IV).
```{r}
cleaned <- read.csv("../data/cleaned_data.csv")
pander(head(cleaned))
```

To set a baseline, the data is run through different types of algorithms in Weka:
```{=latex}
\begin{table}[h!]
    \centering
    \caption{Results algorithm comparison in Weka, `*' = significantly worse; `v' = significantly better}
    \label{tab:weka1}
    \begin{tabular}{@{}lllllll@{}}
        \hline
        \textbf{Algorithm} & \textbf{Speed} & \textbf{Accuracy} & \textbf{Sensitivity} & \textbf{Specificity} & \textbf{ROC} & \textbf{FNR}\\
        \hline
        \hline
        ZeroR & 0.00s & 35.25\% & 0.00 & 1.00 & 0.50 & 1.00\\
        \hline
        OneR & 0.00s & 41.19\% v & 0.48 v & 0.78 * & 0.63 v & 0.52 *\\
        NaiveBayes & 0.00s & 50.07\% v & 0.57 v & 0.82 * & 0.81 v & 0.43 *\\
        SimpleLogistics & 0.04s v & 54.17\% v & 0.51 v & 0.86 * & 0.82 v & 0.49 *\\
        SMO & 0.01s v & 51.17\% v & 0.39 & 0.89 * & 0.78 v & 0.61 *\\
        IBk & 0.00s & 39.25\% & 0.44 v & 0.89 * & 0.66 v & 0.56 *\\
        J48 & 0.01s v & 47.63\% v & 0.60 v & 0.79 * & 0.79 v & 0.40 *\\
        RandomForest & 0.17s v & 53.22\% v & 0.65 v & 0.82 * & 0.84 v & 0.35 *\\
        \hline
    \end{tabular}
\end{table}
```

These results show a relative low sensitivity and high FNR. Some algorithms have a low ROC value, low sensitivity and low accuracy: OneR, IBk, and J48 are not further analysed. OneR will be kept to set a baseline. To apply the CostSensitiveClassifier, the confusion matrix of every algorithm should be known:

```{=latex}
\begin{table}[h!]
    \centering
    \caption{Confusion matrix per algorithm}
    \label{tab:cm1}
    \begin{tabular}{|cccc|c|}
        \multicolumn{5}{c}{\textbf{NaiveBayes}}\\
        \hline
        \hline
        a & b & c & d & classified as\\
        \hline
        105 & 60 & 6 & 12 & a = Control\\
        74 & 96 & 21 & 17 & b = Benign\\
        1 & 23 & 43 & 35 & c = I-II\\
        3 & 10 & 35 & 49 & d = III-IV\\
        \hline
    \end{tabular}
    \begin{tabular}{|cccc|c|}
        \multicolumn{5}{c}{\textbf{SimpleLogistics}}\\
        \hline
        \hline
        a & b & c & d & classified as\\
        \hline
        94 & 85 & 2 & 2 & a = Control\\
        49 & 143 & 11 & 5 & b = Benign\\
        3 & 29 & 42 & 28 & c = I-II\\
        2 & 17 & 35 & 43 & d = III-IV\\
        \hline
    \end{tabular}
    \begin{tabular}{|cccc|c|}
        \multicolumn{5}{c}{\textbf{SMO}}\\
        \hline
        \hline
        a & b & c & d & classified as\\
        \hline
        70 & 112 & 1 & 0 & a = Control\\
        37 & 155 & 11 & 5 & b = Benign\\
        3 & 34 & 42 & 23 & c = I-II\\
        2 & 28 & 32 & 35 & d = III-IV\\
        \hline
    \end{tabular}
    \begin{tabular}{|cccc|c|}
        \multicolumn{5}{c}{\textbf{RandomForest}}\\
        \hline
        \hline
        a & b & c & d & classified as\\
        \hline
        177 & 60 & 0 & 6 & a = Control\\
        57 & 129 & 14 & 8 & b = Benign\\
        8 & 35 & 32 & 27 & c = I-II\\
        5 & 27 & 28 & 37 & d = III-IV\\
        \hline
    \end{tabular}
\end{table}
```

Now the matrices for CostSensitiveClassifier can be build.

## Metrics
For predictive models

## Weka: Model Exploration
