---
author: Lisa Hu
output:
  pdf_document:
    includes:
      before_body: title.sty
      in_header: header.sty
    keep_tex : true
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: yes
    latex_engine: xelatex
---
```{r include = FALSE}
# Copyright (c) 2022 Lisa Hu
# Licensed under GPLv3. See LICENSE
```

```{r setup, include = FALSE, warning = FALSE, message = FALSE, results = "hide"}
#' Setup chunk
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::read_chunk("../src/log.R")
knitr::read_chunk("../src/data_cleaning.R")
source("../src/functions.R", local = knitr::knit_global())
```
[//]: # (toc)

\newpage
# Data description
The data can be found on kaggle.com: [Urinary biomarkers for pancreatic cancer](https://www.kaggle.com/datasets/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer)
The files are saved as `~/data/Data.csv` and `~/data/Documentation.csv` for easier access.

The following packages were used:

+ readr
+ pander
+ dplyr
+ FSA
+ ggplot2
+ ggpubr
+ ggbiplot
+ ggnewscale
+ RWeka

```{r libraries, warning = FALSE, message = FALSE}
#' Load all the packages
packages <- c("readr", "pander", "dplyr", "FSA", "ggplot2", "ggpubr",
              "ggbiplot", "ggnewscale", "RWeka")
invisible(lapply(packages, library, character.only = T))
```

Weka (v3.8.6) was used for the Machine Learning part.

\newpage
# Reading the data
To create an insight on the data, a codebook is generated (see file `~/data/codebook.txt`). This information originates from the `~/data/Documentation.csv`. This file was given with the data file and can be found on the website.
```{r read-data}
```

\newpage
# Manipulate the data
A lot of the rows contain empty strings instead of NA, which has to be fixed first. Besides that, the columns `sample_id` , `patient_cohort`, `sample_origin`, and `benign_sample_diagnosis` in the dataset significant value for the analysis and are therefor dropped. A column `diagnosis_group` was added for a comparison test.

```{r change-data}
```

\newpage
## REG1A vs. REG1B
After the data manipulation, it looks a bit like this:
```{r summary}
```

A lot of missing values can be seen in the REG1A column and imputation is not an option: Any type of imputation here can lead to data imbalance. REG1A and REG1B are very much alike, since both are regenerative proteins for the pancreas. Maybe a significance in performance can be traced when compared to each other:
\newpage
```{r reg-vs}
```

Although performance between the two is similar, a Kruskal-Wallis test with Dunn's multiple comparisons shows that REG1B outperforms REG1A when the control and benign samples are compared to the I-IIA PDAC samples. Therefor, REG1B was used further on in the experiments and REG1A is dropped.

\newpage
## Log transformation
The summary earlier also showed very high maximum values, but rather low medians.
A log-transformation is applied to correct this.

```{r log-trans}
```

The samples are then grouped by diagnosis for easier access of the different samples.
Table \ref{tab:demo} shows the different amounts of samples per diagnosis and Table \ref{tab:blood} shows the amount of which are also blood samples.
\newpage
```{r demograph}
```

\newpage
# Analyse the data
It is important to know which variables are important and how they interact with each other. This chapter will focus on that with different methods.

## Boxplots

```{r exp-box, fig.height = 8, fig.cap = "\\label{fig:box}Boxplots visualizing the spreads of the different biomarkers per diagnosis."}
```

(Boxplots print on the next page)

The boxplots show that outliers are not localized in a specific diagnosis group, but rather spread over the groups, and the biomarkers are more expressed in the PDAC patients than the "healthy" groups.

\newpage

## Correlation matrix

```{r correlation, fig.cap = "\\label{fig:cor}Heatmap of how correlated the different variables are. Gradient:correlation = dark-light:1-0"}
```

The heatmap shows that there is not much correlation between creatinine and age, and the other variables.
The other outstanding one has to be the TFF1 biomarker, being the most correlated variable to others.

\newpage

## PCA
A principal component analysis (PCA) enables the visualization of multidimensional data. The vectors in the plot indicate how related the variables are with each other: an angle <90&deg; = positively correlated, ~90&deg; = low correlation, >&deg; = negatively correlated. To determine the angle, take one vector and measure clockwise to the next vector. Every point close to the origin have values close to the mean for all variables.

```{r pca, fig.cap = "\\label{fig:pca}PCA plot using PC1 and PC2. The colors indicate the diagnosis: 1 = Control, 2 = Benign, 3 = PDAC"}
```

While the control and benign group show relative distance from the PDAC group, there is a still a lot of overlapping samples with the benign and PDAC groups. As earlier concluded from the heatmap, the creatinine and age variables are not that correlated to the other variables. REG1B and LYVE1 are basically on top of each other, with TFF1 really close.

\newpage
# Machine Learning
## Quality Metrics
Accuracy is the most important quality metric to measure the performance of an algorithm. Though it is easy to choose an algorithm this way, there are always multiple algorithms one can take as final option. Hence, other quality metrics have to be taken in account to make the optimal choice.

For this project, the model is a finished product, trained and tested with the already collected data. New samples for this model are manually inserted by the acting physician, thus speed is not a relevant metric. Naturally, it is of more importance a patient with a malignant cancer should not be classified as benign, rather than a patient with a benign case being classified as malignant. These errors can be visualized in a confusion matrix, which almost all algorithms output.

### Confusion Matrix
A standard confusion matrix is a 2x2 matrix which shows all the correct hits and rejections, and errors. In Weka and based on the project, a confusion matrix looks a bit like this:
```{=latex}
\begin{table}[h]
    \centering
    \caption{Example of a confusion matrix}
    \label{tab:ex_cm}
    \begin{tabular}{cc|l}
        a & b & <- classified as\\
        \hline
        TP & FN & a = Control/Benign (healthy)\\
        FP & TN & b = Malignant\\
    \end{tabular}
\end{table}
```

In this example, the correctly classified "healthy" instances are true positive (TP) and correctly classified "Malignant" instances are true negative (TN). The "healthy" instances that were classified as "Malignant" are false positive (FP) and malignant instances that were classified as benign are false negative (FN).

### Sensitivity and False Positive Rate
Generally important for machine learning algorithms, but also for this project: Sensitivity and False Positive Rate (FPR). Also known as the true positive rate (TPR), sensitivity is calculated as $\frac{TP}{TP+FN}$. The FPR is calculated as $\frac{FP}{FP+TN}$.

### Area under ROC
The receiver operating characteristic (ROC) curve is graphical plot that shows the ability of the algorithm, by plotting the TPR against the FPR.

\newpage
## Weka: Model exploration
For the exploration of the model, the data is cleaned it contains only the biomarkers and the classification labels (Control, Benign or PDAC).
```{r cleaning, eval = FALSE}
```

The `~/data/wekafiles/base.exp` file contains all the options used for a baseline run in Weka. The data is run through different types of algorithms with 10-fold cross validation:
```{r weka-base}
```

These results show a relative low accuracy and sensitivity. Some algorithms also have a low ROC value, putting the cutoff at 0.8: OneR, SMO, IBk and J48 will not be used. As for the remaining three: NaiveBayes has by far the lowest accuracy of them and is therefor also dropped. Leaving the options Logistic and RandomForest. Since earlier shown there is a linear correlation between the different variables, the Logistic algorithm would be more fitting for this type of data.

\newpage
### Data imbalance
To prepare the data for the optimization, the data needs to be split into groups: one file containing `Control` and `PDAC` samples, another file containing `Benign` and `PDAC` samples:
```{r splitting, eval = FALSE}
```

### Algorithm optimization
For the optimization of the algorithm, Weka's ThresholdSelector classifier will be used. This algorithm allows a threshold on the probability output of the given classifier. It is important that the FPR is as low as possible, since no patient wants to be diagnosed healthy when there is something serious swarming around. Therefor, the ThresholdSelector's designated class is set to `second class value`, since the "PDAC" instances are after the healthy instances. The measure to set the threshold is TPR.  Again, these options can be imported from `~/data/wekafiles/optimization.exp`.
```{r optimization}
```

The results of the `Logistic` classifier shows the base algorithm without the optimization. Though the accuracy is high, the FPR is too. The FPR needs to be as low as possible without the expense of the accuracy and TPR, so the highest TPR and lowest FPR possible. Using the `Analyse` tab in the Weka Experimenter, Paired T-Tests can be performed to see which algorithm is significant different on the given comparison field. Comparing with a significance of 0.05, the best option for the Control model is the one with a cutoff of 0.600, whereas the Benign model would be best with a cutoff of 0.550. These two highest cutoffs that show no significant raise in FPR when compared to the Logistic algorithm.

\newpage
### ROC curve

[//]: # (TODO)
```{r roc, fig.cap = "\\label{fig:roc}ROC curve of the two models. Gradient shows the thresholds"}
```
